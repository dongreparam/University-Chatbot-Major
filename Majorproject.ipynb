{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pdfplumber\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Step 1: Setup NLTK stop words\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Step 2: Initialize the embedding model and ChromaDB client\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "client = chromadb.Client()\n",
        "\n",
        "# Step 3: Read and split text from the PDF\n",
        "pdf_text = []\n",
        "with pdfplumber.open(\"questions.pdf\") as pdf:\n",
        "    for page in pdf.pages:\n",
        "        pdf_text.append(page.extract_text())\n",
        "\n",
        "# Step 4: Tokenize the text into sentences and remove stop words\n",
        "sentences = []\n",
        "for text in pdf_text:\n",
        "    # Split text into sentences using simple split (you can use nltk or regex for better accuracy)\n",
        "    sentences += [sentence for sentence in text.split('.') if sentence]\n",
        "\n",
        "# Remove stop words from sentences\n",
        "sentences = [\" \".join([word for word in sentence.split() if word.lower() not in stop_words]) for sentence in sentences]\n",
        "\n",
        "# Step 5: Take user input\n",
        "user_query = input(\"Enter your search query: \")\n",
        "cleaned_query = \" \".join([word for word in user_query.split() if word.lower() not in stop_words])  # Remove stop words from query\n",
        "\n",
        "# Step 6: Embed sentences and the query\n",
        "query_embedding = embed_model.encode(cleaned_query)\n",
        "sentence_embeddings = embed_model.encode(sentences)\n",
        "\n",
        "# Step 7: Calculate cosine similarity and find the closest sentence\n",
        "similarity_scores = util.pytorch_cos_sim(query_embedding, sentence_embeddings)\n",
        "\n",
        "# Find the index of the most similar sentence\n",
        "most_similar_index = similarity_scores.argmax()\n",
        "most_similar_sentence = sentences[most_similar_index]\n",
        "\n",
        "# Step 8: Print the most similar sentence\n",
        "print(\"Most similar sentence:\", most_similar_sentence)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBoH4lneDOTo",
        "outputId": "d7813b19-1891-46df-d9df-7d607f11b883"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your search query: culture\n",
            "Most similar sentence: Campus Lifeand Culture: - arethemajorcultural eventsandfestivalscelebrated oncampus? - Arethere anystudentclubsor societiesIcan join? HowdoI becomeamember? - Howdoestheuniversity supportextracurricularactivitiesandhobbies? - Arethere anyvolunteeringopportunities available students? 2\n"
          ]
        }
      ]
    }
  ]
}